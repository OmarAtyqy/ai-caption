{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# enable auto reload of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to load and preprocess the data, as well as train our own captioning model from scratch. If you want to use the model directly, please refer to the `main.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was made to be modular, in such a way that you can run only the section that you want. However, some sections may require the output of the previous section to work properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the annotation data\n",
    "df = load_raw_captions_data(\"./data/captions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the caption dictionary\n",
    "captions_dic = generate_captions_dic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 31783\n",
      "Number of captions per image: 5\n",
      "Total number of captions: 158915\n"
     ]
    }
   ],
   "source": [
    "# print info about the caption dictionary\n",
    "n_images = len(captions_dic)\n",
    "n_captions_per_image = len(next(iter(captions_dic.values())))\n",
    "n_captions = n_images * n_captions_per_image\n",
    "\n",
    "print(f\"Number of images: {n_images}\")\n",
    "print(f\"Number of captions per image: {n_captions_per_image}\")\n",
    "print(f\"Total number of captions: {n_captions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31783/31783 [00:00<00:00, 62322.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# clean the captions by removing any special characters and converting to lower case\n",
    "captions_dic = clean_captions(captions_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions for the first image:\n",
      "two young guys with shaggy hair look at their hands while hanging out in the yard\n",
      "two young white males are outside near many bushes\n",
      "two men in green shirts are standing in a yard\n",
      "a man in a blue shirt standing in a garden\n",
      "two friends enjoy time spent together\n"
     ]
    }
   ],
   "source": [
    "# print tha captions for the first image\n",
    "print(f\"Captions for the first image:\")\n",
    "for cap in next(iter(captions_dic.values())):\n",
    "    print(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31783/31783 [00:00<00:00, 168730.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 18288 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary\n",
    "vocab = build_vocab(captions_dic)\n",
    "\n",
    "# print the size of the vocabulary\n",
    "print(f\"Vocabulary size: {len(vocab)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the captions dictionary\n",
    "save_captions_dic(captions_dic, \"./data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
