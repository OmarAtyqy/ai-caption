{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# enable auto reload of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used to load and preprocess the data, as well as train our own captioning model from scratch. If you want to use the model directly, please refer to the `main.py` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.data_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the annotation data\n",
    "df = load_raw_captions_data(\"./data/captions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the caption dictionary\n",
    "captions_dic = generate_captions_dic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 31783\n",
      "Number of captions per image: 5\n",
      "Total number of captions: 158915\n"
     ]
    }
   ],
   "source": [
    "# print info about the caption dictionary\n",
    "n_images = len(captions_dic)\n",
    "n_captions_per_image = len(next(iter(captions_dic.values())))\n",
    "n_captions = n_images * n_captions_per_image\n",
    "\n",
    "print(f\"Number of images: {n_images}\")\n",
    "print(f\"Number of captions per image: {n_captions_per_image}\")\n",
    "print(f\"Total number of captions: {n_captions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31783/31783 [00:00<00:00, 62322.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# clean the captions by removing any special characters and converting to lower case\n",
    "captions_dic = clean_captions(captions_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captions for the first image:\n",
      "two young guys with shaggy hair look at their hands while hanging out in the yard\n",
      "two young white males are outside near many bushes\n",
      "two men in green shirts are standing in a yard\n",
      "a man in a blue shirt standing in a garden\n",
      "two friends enjoy time spent together\n"
     ]
    }
   ],
   "source": [
    "# print tha captions for the first image\n",
    "print(f\"Captions for the first image:\")\n",
    "for cap in next(iter(captions_dic.values())):\n",
    "    print(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31783/31783 [00:00<00:00, 168730.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 18288 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary\n",
    "vocab = build_vocab(captions_dic)\n",
    "\n",
    "# print the size of the vocabulary\n",
    "print(f\"Vocabulary size: {len(vocab)} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/processed_captions.txt\\\\processed_data.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# save the captions dictionary\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m save_captions_dic(captions_dic, \u001b[39m\"\u001b[39;49m\u001b[39m./data/processed_captions.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\elaty\\OneDrive\\Documents\\Projects\\Caption Generation Using Deep Learning\\src\\utils\\data_utils.py:86\u001b[0m, in \u001b[0;36msave_captions_dic\u001b[1;34m(captions_dic, path)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[39mSave the captions dictionary to a json file\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     85\u001b[0m filename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(path, \u001b[39m\"\u001b[39m\u001b[39mprocessed_data.json\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m\"\u001b[39;49m\u001b[39mw\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     87\u001b[0m     json\u001b[39m.\u001b[39mdump(captions_dic, f)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/processed_captions.txt\\\\processed_data.json'"
     ]
    }
   ],
   "source": [
    "# save the captions dictionary\n",
    "save_captions_dic(captions_dic, \"./data/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Machine Learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
